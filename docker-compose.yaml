services:
  db:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: riskops
      POSTGRES_USER: riskops
      POSTGRES_PASSWORD: riskops
    ports:
      - "6432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./infra/db/init:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB"]
      interval: 5s
      timeout: 5s
      retries: 10

  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    command: >
      sh -c "python -m pip install --no-cache-dir -q psycopg2-binary && mlflow server
      --host 0.0.0.0
      --port 3000
      --allowed-hosts mlflow,mlflow:3000,localhost,localhost:3000,127.0.0.1,127.0.0.1:3000
      --backend-store-uri postgresql://riskops:riskops@db:5432/riskops?options=-csearch_path%3Dmlflow
      --default-artifact-root /mlflow/artifacts"
    ports:
      - "3000:3000"
    volumes:
      - mlflow_artifacts:/mlflow/artifacts
    environment:
      MLFLOW_TRACKING_URI: http://localhost:3000
    depends_on:
      db:
        condition: service_healthy

  airflow-init:
    image: apache/airflow:2.9.3
    environment: &airflow-env
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "false"
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://riskops:riskops@db:5432/riskops
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "true"
      DATABASE_URL: postgresql://riskops:riskops@db:5432/riskops
      MLFLOW_TRACKING_URI: http://mlflow:3000
      _AIRFLOW_WWW_USER_USERNAME: admin
      _AIRFLOW_WWW_USER_PASSWORD: admin
    volumes:
      - ./infra/airflow/dags:/opt/airflow/dags
      - airflow_logs:/opt/airflow/logs
    depends_on:
      db:
        condition: service_healthy
    command: >
      bash -lc "
      airflow db migrate &&
      airflow users create --username \"$${_AIRFLOW_WWW_USER_USERNAME}\" --password \"$${_AIRFLOW_WWW_USER_PASSWORD}\" --firstname Admin --lastname User --role Admin --email admin@example.com
      "

  airflow-webserver:
    image: apache/airflow:2.9.3
    environment: *airflow-env
    ports:
      - "8080:8080"
    volumes:
      - ./infra/airflow/dags:/opt/airflow/dags
      - airflow_logs:/opt/airflow/logs
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    command: webserver
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8080/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 15

  airflow-scheduler:
    image: apache/airflow:2.9.3
    environment: *airflow-env
    volumes:
      - ./infra/airflow/dags:/opt/airflow/dags
      - airflow_logs:/opt/airflow/logs
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    command: scheduler

  frontend:
    image: node:20-alpine
    working_dir: /app
    command: sh -c "npm ci && npm run dev -- --host 0.0.0.0 --port 5173"
    ports:
      - "5173:5173"
    volumes:
      - ./ui:/app
      - /app/node_modules
    environment:
      # если понадобится подключаться к Postgres из фронта/прокси
      DATABASE_URL: postgresql://riskops:riskops@db:5432/riskops
    depends_on:
      db:
        condition: service_healthy

  pipelines:
    build:
      context: ./apps/pipelines
      dockerfile: Dockerfile
    environment:
      DATABASE_URL: postgresql://riskops:riskops@db:5432/riskops
      MLFLOW_TRACKING_URI: http://mlflow:3000
    depends_on:
      db:
        condition: service_healthy
      mlflow:
        condition: service_started
    # utility container; used by `docker compose run --rm pipelines <cmd>`
    entrypoint: ["python", "-m", "riskops_pipelines"]

volumes:
  postgres_data:
  mlflow_artifacts:
  airflow_logs:
